
======================================================================
num_words = 1 | batch_size = 5
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='s' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='s' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1

[Batch Summary for n_words=1]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 100.00%

======================================================================
num_words = 2 | batch_size = 5
Baseline | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='on' | pos_acc=1/2 (50.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='sm' | pos_acc=0/2 (0.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='ry' | pos_acc=1/2 (50.0%) | compared=2
Baseline | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='oo' | pos_acc=0/2 (0.0%) | compared=2

[Batch Summary for n_words=2]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 40.00%

======================================================================
num_words = 3 | batch_size = 5
Baseline | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='cne' | pos_acc=2/3 (66.7%) | compared=3
Baseline | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='edn' | pos_acc=1/3 (33.3%) | compared=3
Baseline | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='ien' | pos_acc=2/3 (66.7%) | compared=3
Baseline | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3

[Batch Summary for n_words=3]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 73.33%

======================================================================
num_words = 4 | batch_size = 5
Baseline | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='yyy' | pos_acc=1/4 (25.0%) | compared=3 | len_mismatch(gold=4, pred=3)
Baseline | pred='myn' | pos_acc=3/4 (75.0%) | compared=3 | len_mismatch(gold=4, pred=3)
CoT      | pred='myny' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='myny' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='ryyn' | pos_acc=1/4 (25.0%) | compared=4
Baseline | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='yyyye' | pos_acc=3/4 (75.0%) | compared=4 | len_mismatch(gold=4, pred=5)
L2M-DV   | pred='nyye' | pos_acc=3/4 (75.0%) | compared=4
Baseline | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='ggn' | pos_acc=0/4 (0.0%) | compared=3 | len_mismatch(gold=4, pred=3)
Baseline | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='tyee' | pos_acc=3/4 (75.0%) | compared=4

[Batch Summary for n_words=4]
  Baseline  : 95.00%
  CoT       : 100.00%
  L2M       : 95.00%
  L2M-DV    : 40.00%

======================================================================
num_words = 5 | batch_size = 5
Baseline | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='eycyn' | pos_acc=0/5 (0.0%) | compared=5
Baseline | pred='yxeyn' | pos_acc=3/5 (60.0%) | compared=5
CoT      | pred='yxyen' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='yxeyn' | pos_acc=3/5 (60.0%) | compared=5
L2M-DV   | pred='gxyen' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='ynnsl' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='ynnsl' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='cnnsn' | pos_acc=3/5 (60.0%) | compared=5
L2M-DV   | pred='nysnl' | pos_acc=1/5 (20.0%) | compared=5
Baseline | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='enyyy' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='yyyyy' | pos_acc=4/5 (80.0%) | compared=5
CoT      | pred='yyyym' | pos_acc=3/5 (60.0%) | compared=5
L2M      | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='yyyyy' | pos_acc=4/5 (80.0%) | compared=5

[Batch Summary for n_words=5]
  Baseline  : 88.00%
  CoT       : 92.00%
  L2M       : 84.00%
  L2M-DV    : 52.00%

======================================================================
num_words = 6 | batch_size = 5
Baseline | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='enyryl' | pos_acc=5/6 (83.3%) | compared=6
L2M-DV   | pred='erymyl' | pos_acc=5/6 (83.3%) | compared=6
Baseline | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nyeeyl' | pos_acc=5/6 (83.3%) | compared=6
L2M      | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='nyeeyl' | pos_acc=5/6 (83.3%) | compared=6
Baseline | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='yyyyyy' | pos_acc=3/6 (50.0%) | compared=6
Baseline | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ynlmy' | pos_acc=5/6 (83.3%) | compared=5 | len_mismatch(gold=6, pred=5)
L2M-DV   | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
Baseline | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='nnnnyy' | pos_acc=5/6 (83.3%) | compared=6
L2M-DV   | pred='niiney' | pos_acc=2/6 (33.3%) | compared=6

[Batch Summary for n_words=6]
  Baseline  : 100.00%
  CoT       : 96.67%
  L2M       : 90.00%
  L2M-DV    : 70.00%

======================================================================
num_words = 7 | batch_size = 5
Baseline | pred='yyyynny' | pos_acc=6/7 (85.7%) | compared=7
CoT      | pred='yyyynny' | pos_acc=6/7 (85.7%) | compared=7
L2M      | pred='yyynnny' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='iyyyyyn' | pos_acc=2/7 (28.6%) | compared=7
Baseline | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
CoT      | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
L2M      | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
L2M-DV   | pred='nsmnnyy' | pos_acc=5/7 (71.4%) | compared=7
Baseline | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='mnnynln' | pos_acc=5/7 (71.4%) | compared=7
Baseline | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='nynnysl' | pos_acc=4/7 (57.1%) | compared=7
Baseline | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='nyyyyny' | pos_acc=5/7 (71.4%) | compared=7
L2M      | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='nyyyyyy' | pos_acc=6/7 (85.7%) | compared=7

[Batch Summary for n_words=7]
  Baseline  : 94.29%
  CoT       : 88.57%
  L2M       : 97.14%
  L2M-DV    : 62.86%

======================================================================
num_words = 8 | batch_size = 5
Baseline | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='yennsccn' | pos_acc=6/8 (75.0%) | compared=8
L2M-DV   | pred='yennnnsc' | pos_acc=5/8 (62.5%) | compared=8
Baseline | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='nmsnyey' | pos_acc=5/8 (62.5%) | compared=7 | len_mismatch(gold=8, pred=7)
L2M-DV   | pred='nmsnyey' | pos_acc=5/8 (62.5%) | compared=7 | len_mismatch(gold=8, pred=7)
Baseline | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
Baseline | pred='eyyyyyyn' | pos_acc=5/8 (62.5%) | compared=8
CoT      | pred='eyyyynny' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='eyyyyynn' | pos_acc=6/8 (75.0%) | compared=8
L2M-DV   | pred='nnnnnyyy' | pos_acc=1/8 (12.5%) | compared=8
Baseline | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='ynmynel' | pos_acc=7/8 (87.5%) | compared=7 | len_mismatch(gold=8, pred=7)
L2M      | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8

[Batch Summary for n_words=8]
  Baseline  : 92.50%
  CoT       : 97.50%
  L2M       : 82.50%
  L2M-DV    : 67.50%

======================================================================
num_words = 9 | batch_size = 5
Baseline | pred='nyynlnnn' | pos_acc=5/9 (55.6%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nyyylnnnn' | pos_acc=7/9 (77.8%) | compared=9
L2M      | pred='nyynlnnn' | pos_acc=5/9 (55.6%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M-DV   | pred='nnnnnnnnn' | pos_acc=5/9 (55.6%) | compared=9
Baseline | pred='nnnnnnxy' | pos_acc=6/9 (66.7%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nnnnnxy' | pos_acc=6/9 (66.7%) | compared=7 | len_mismatch(gold=9, pred=7)
L2M      | pred='ynnnnxy' | pos_acc=5/9 (55.6%) | compared=7 | len_mismatch(gold=9, pred=7)
L2M-DV   | pred='nnnnyxyy' | pos_acc=5/9 (55.6%) | compared=8 | len_mismatch(gold=9, pred=8)
Baseline | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='nyyglgnyy' | pos_acc=4/9 (44.4%) | compared=9
Baseline | pred='nnelnexy' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nnelnexy' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M      | pred='nnelnexy' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M-DV   | pred='nnelnxy' | pos_acc=3/9 (33.3%) | compared=7 | len_mismatch(gold=9, pred=7)
Baseline | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='yymnnnnny' | pos_acc=8/9 (88.9%) | compared=9
L2M      | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='yomlnnnny' | pos_acc=8/9 (88.9%) | compared=9

[Batch Summary for n_words=9]
  Baseline  : 73.33%
  CoT       : 75.56%
  L2M       : 71.11%
  L2M-DV    : 55.56%

======================================================================
num_words = 10 | batch_size = 5
Baseline | pred='nnnyyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10 | len_mismatch(gold=10, pred=11)
CoT      | pred='nnnyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10
L2M      | pred='nnnyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10
L2M-DV   | pred='nnnnnyyyyy' | pos_acc=8/10 (80.0%) | compared=10
Baseline | pred='nynyylmnen' | pos_acc=10/10 (100.0%) | compared=10
CoT      | pred='nynylmlnen' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nynnlymnen' | pos_acc=7/10 (70.0%) | compared=10
L2M-DV   | pred='nynylymnen' | pos_acc=8/10 (80.0%) | compared=10
Baseline | pred='nnsynenln' | pos_acc=4/10 (40.0%) | compared=9 | len_mismatch(gold=10, pred=9)
CoT      | pred='nnsyneennl' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nnsynenl' | pos_acc=3/10 (30.0%) | compared=8 | len_mismatch(gold=10, pred=8)
L2M-DV   | pred='nnsyennnl' | pos_acc=5/10 (50.0%) | compared=9 | len_mismatch(gold=10, pred=9)
Baseline | pred='neleeneeymt' | pos_acc=7/10 (70.0%) | compared=10 | len_mismatch(gold=10, pred=11)
CoT      | pred='teleneeymt' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nelleeneymt' | pos_acc=4/10 (40.0%) | compared=10 | len_mismatch(gold=10, pred=11)
L2M-DV   | pred='nelenteymt' | pos_acc=8/10 (80.0%) | compared=10
Baseline | pred='yymelynnxy' | pos_acc=6/10 (60.0%) | compared=10
CoT      | pred='yymeilynnx' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='yymeyynnyy' | pos_acc=8/10 (80.0%) | compared=10
L2M-DV   | pred='yymelynnxy' | pos_acc=6/10 (60.0%) | compared=10

[Batch Summary for n_words=10]
  Baseline  : 74.00%
  CoT       : 76.00%
  L2M       : 64.00%
  L2M-DV    : 70.00%

======================================================================
num_words = 11 | batch_size = 5
Baseline | pred='nyynmyynl' | pos_acc=9/11 (81.8%) | compared=9 | len_mismatch(gold=11, pred=9)
CoT      | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nymnmylye' | pos_acc=5/11 (45.5%) | compared=9 | len_mismatch(gold=11, pred=9)
Baseline | pred='nnyslytlmly' | pos_acc=8/11 (72.7%) | compared=11
CoT      | pred='nnyslytnmny' | pos_acc=8/11 (72.7%) | compared=11
L2M      | pred='nnyssyltnmy' | pos_acc=5/11 (45.5%) | compared=11
L2M-DV   | pred='nnysyltnmy' | pos_acc=9/11 (81.8%) | compared=10 | len_mismatch(gold=11, pred=10)
Baseline | pred='nyectmnnymy' | pos_acc=7/11 (63.6%) | compared=11
CoT      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nyecytmnny' | pos_acc=9/11 (81.8%) | compared=10 | len_mismatch(gold=11, pred=10)
Baseline | pred='mnlryyymnn' | pos_acc=10/11 (90.9%) | compared=10 | len_mismatch(gold=11, pred=10)
CoT      | pred='mnlyyyymnnn' | pos_acc=10/11 (90.9%) | compared=11
L2M      | pred='mnltyymnnn' | pos_acc=7/11 (63.6%) | compared=10 | len_mismatch(gold=11, pred=10)
L2M-DV   | pred='mnlryymnnn' | pos_acc=8/11 (72.7%) | compared=10 | len_mismatch(gold=11, pred=10)
Baseline | pred='yyennynncen' | pos_acc=11/11 (100.0%) | compared=11
CoT      | pred='yyennynncen' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='yyenngnncen' | pos_acc=10/11 (90.9%) | compared=11
L2M-DV   | pred='yyenyncnenn' | pos_acc=6/11 (54.5%) | compared=11

[Batch Summary for n_words=11]
  Baseline  : 81.82%
  CoT       : 92.73%
  L2M       : 80.00%
  L2M-DV    : 67.27%

======================================================================
num_words = 12 | batch_size = 5
Baseline | pred='nsnylynyynny' | pos_acc=12/12 (100.0%) | compared=12
CoT      | pred='nsnylynnyny' | pos_acc=9/12 (75.0%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='nsnlynnnyy' | pos_acc=5/12 (41.7%) | compared=10 | len_mismatch(gold=12, pred=10)
L2M-DV   | pred='nsnlynyynny' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='enynyygynen' | pos_acc=7/12 (58.3%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='enyynysgynen' | pos_acc=8/12 (66.7%) | compared=12
L2M      | pred='enynyysgyen' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='enynyygsnyn' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='eyynyyyyynmn' | pos_acc=9/12 (75.0%) | compared=12
CoT      | pred='eynnnyyynmmn' | pos_acc=8/12 (66.7%) | compared=12
L2M      | pred='eynnyyyynmn' | pos_acc=7/12 (58.3%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='eennnnyyylm' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='ynyyynnmyre' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='ynynnnymrye' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='ynyyyynnnnnn' | pos_acc=5/12 (41.7%) | compared=12
L2M-DV   | pred='ynynlmyrye' | pos_acc=4/12 (33.3%) | compared=10 | len_mismatch(gold=12, pred=10)

[Batch Summary for n_words=12]
  Baseline  : 73.33%
  CoT       : 68.33%
  L2M       : 60.00%
  L2M-DV    : 55.00%

======================================================================
num_words = 13 | batch_size = 5
Baseline | pred='ynyyyyylnn' | pos_acc=6/13 (46.2%) | compared=10 | len_mismatch(gold=13, pred=10)
CoT      | pred='ynynyyyl' | pos_acc=6/13 (46.2%) | compared=8 | len_mismatch(gold=13, pred=8)
L2M      | pred='ynynnyylnyyny' | pos_acc=10/13 (76.9%) | compared=13
L2M-DV   | pred='ynynynlynyny' | pos_acc=5/13 (38.5%) | compared=12 | len_mismatch(gold=13, pred=12)
Baseline | pred='nycgnynyyecn' | pos_acc=12/13 (92.3%) | compared=12 | len_mismatch(gold=13, pred=12)
CoT      | pred='nycgnynyyecnl' | pos_acc=13/13 (100.0%) | compared=13
L2M      | pred='tlygngyctyiyg' | pos_acc=2/13 (15.4%) | compared=13
L2M-DV   | pred='nycgnynyecln' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
Baseline | pred='nnynnnneyml' | pos_acc=8/13 (61.5%) | compared=11 | len_mismatch(gold=13, pred=11)
CoT      | pred='nnynnnneeymly' | pos_acc=13/13 (100.0%) | compared=13
L2M      | pred='nnnnntnrrn' | pos_acc=5/13 (38.5%) | compared=10 | len_mismatch(gold=13, pred=10)
L2M-DV   | pred='nnynnneeymly' | pos_acc=7/13 (53.8%) | compared=12 | len_mismatch(gold=13, pred=12)
Baseline | pred='ynnsrlnnngyl' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
CoT      | pred='ynnsrlnnnngyl' | pos_acc=13/13 (100.0%) | compared=13
L2M      | pred='onotetdtdn' | pos_acc=2/13 (15.4%) | compared=10 | len_mismatch(gold=13, pred=10)
L2M-DV   | pred='ynnsrlnnngyl' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
Baseline | pred='nlnnynely' | pos_acc=6/13 (46.2%) | compared=9 | len_mismatch(gold=13, pred=9)
CoT      | pred='nlnnynynyl' | pos_acc=8/13 (61.5%) | compared=10 | len_mismatch(gold=13, pred=10)
L2M      | pred='nlnnyynyenyl' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='tlnnyynely' | pos_acc=4/13 (30.8%) | compared=10 | len_mismatch(gold=13, pred=10)

[Batch Summary for n_words=13]
  Baseline  : 63.08%
  CoT       : 81.54%
  L2M       : 43.08%
  L2M-DV    : 52.31%

======================================================================
num_words = 14 | batch_size = 5
Baseline | pred='nnslnnnnnnml' | pos_acc=7/14 (50.0%) | compared=12 | len_mismatch(gold=14, pred=12)
CoT      | pred='nnnslnnnnnml' | pos_acc=10/14 (71.4%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M      | pred='nnnslnnnnnnnn' | pos_acc=12/14 (85.7%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='nnslnnnnnnml' | pos_acc=7/14 (50.0%) | compared=12 | len_mismatch(gold=14, pred=12)
Baseline | pred='lenynneellyy' | pos_acc=7/14 (50.0%) | compared=12 | len_mismatch(gold=14, pred=12)
CoT      | pred='lenyneelyylyey' | pos_acc=14/14 (100.0%) | compared=14
L2M      | pred='tveicncyy' | pos_acc=1/14 (7.1%) | compared=9 | len_mismatch(gold=14, pred=9)
L2M-DV   | pred='lenynelilyey' | pos_acc=8/14 (57.1%) | compared=12 | len_mismatch(gold=14, pred=12)
Baseline | pred='nynynennyynyt' | pos_acc=10/14 (71.4%) | compared=13 | len_mismatch(gold=14, pred=13)
CoT      | pred='nyynyeennnytn' | pos_acc=7/14 (50.0%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M      | pred='nyyynnnnnnnnnnn' | pos_acc=7/14 (50.0%) | compared=14 | len_mismatch(gold=14, pred=15)
L2M-DV   | pred='nynyenyynynyn' | pos_acc=5/14 (35.7%) | compared=13 | len_mismatch(gold=14, pred=13)
Baseline | pred='lynnlynnyny' | pos_acc=5/14 (35.7%) | compared=11 | len_mismatch(gold=14, pred=11)
CoT      | pred='lyynnnlnynyl' | pos_acc=9/14 (64.3%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M      | pred='lyynnnlnyyyny' | pos_acc=10/14 (71.4%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='nynyynnyynnyyn' | pos_acc=5/14 (35.7%) | compared=14
Baseline | pred='lynnncsslnnnnn' | pos_acc=14/14 (100.0%) | compared=14
CoT      | pred='lynncnsslnnnnn' | pos_acc=12/14 (85.7%) | compared=14
L2M      | pred='nityononrtnn' | pos_acc=2/14 (14.3%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M-DV   | pred='nynncnsslnnnnn' | pos_acc=11/14 (78.6%) | compared=14

[Batch Summary for n_words=14]
  Baseline  : 61.43%
  CoT       : 74.29%
  L2M       : 45.71%
  L2M-DV    : 51.43%

======================================================================
num_words = 15 | batch_size = 5
Baseline | pred='ymyyyyyenmeny' | pos_acc=12/15 (80.0%) | compared=13 | len_mismatch(gold=15, pred=13)
CoT      | pred='ymyyyyneemnnyyy' | pos_acc=11/15 (73.3%) | compared=15
L2M      | pred='ysmnlyclyyiydtyeey' | pos_acc=2/15 (13.3%) | compared=15 | len_mismatch(gold=15, pred=18)
L2M-DV   | pred='ymyyyyynemyneeyy' | pos_acc=9/15 (60.0%) | compared=15 | len_mismatch(gold=15, pred=16)
Baseline | pred='yynelyenycnnyn' | pos_acc=6/15 (40.0%) | compared=14 | len_mismatch(gold=15, pred=14)
CoT      | pred='yyneyleycnyyn' | pos_acc=8/15 (53.3%) | compared=13 | len_mismatch(gold=15, pred=13)
L2M      | pred='ycllynlyclyclyclyclyclyc' | pos_acc=5/15 (33.3%) | compared=15 | len_mismatch(gold=15, pred=24)
L2M-DV   | pred='yynenylencynyn' | pos_acc=6/15 (40.0%) | compared=14 | len_mismatch(gold=15, pred=14)
Baseline | pred='mynnyysyenlty' | pos_acc=4/15 (26.7%) | compared=13 | len_mismatch(gold=15, pred=13)
CoT      | pred='mynnyyseynelety' | pos_acc=7/15 (46.7%) | compared=15
L2M      | pred='smnllnlydssgtnc' | pos_acc=2/15 (13.3%) | compared=15
L2M-DV   | pred='mynnnyyseynelety' | pos_acc=10/15 (66.7%) | compared=15 | len_mismatch(gold=15, pred=16)
Baseline | pred='eeyssnynnyynny' | pos_acc=7/15 (46.7%) | compared=14 | len_mismatch(gold=15, pred=14)
CoT      | pred='eeysnynynynyn' | pos_acc=9/15 (60.0%) | compared=13 | len_mismatch(gold=15, pred=13)
L2M      | pred='eeeityyiyyeyyeyy' | pos_acc=7/15 (46.7%) | compared=15 | len_mismatch(gold=15, pred=16)
L2M-DV   | pred='eeysnynnyynny' | pos_acc=13/15 (86.7%) | compared=13 | len_mismatch(gold=15, pred=13)
Baseline | pred='nnnnyynnnlyen' | pos_acc=8/15 (53.3%) | compared=13 | len_mismatch(gold=15, pred=13)
CoT      | pred='nnnneyynnyllnen' | pos_acc=15/15 (100.0%) | compared=15
L2M      | pred='nnnnnnnnnnnnnnn' | pos_acc=8/15 (53.3%) | compared=15
L2M-DV   | pred='nnyynyyynllnen' | pos_acc=6/15 (40.0%) | compared=14 | len_mismatch(gold=15, pred=14)

[Batch Summary for n_words=15]
  Baseline  : 49.33%
  CoT       : 66.67%
  L2M       : 32.00%
  L2M-DV    : 58.67%
----------------------------------------------------------------------
Average position-wise accuracy (Macro / Micro) | Exact Match
Baseline : 83.07% / 75.17% | EM: 53.33%
CoT      : 87.32% / 81.83% | EM: 58.67%
L2M      : 76.30% / 65.33% | EM: 46.67%
L2M-DV   : 61.06% / 59.17% | EM: 14.67%

======================================================================
Position-wise Accuracy by Number of Words (%)
======================================================================
 n_words |   Baseline |        CoT |        L2M |     L2M-DV
----------------------------------------------------------------------
       1 |     100.00 |     100.00 |     100.00 |     100.00
       2 |     100.00 |     100.00 |     100.00 |      40.00
       3 |     100.00 |     100.00 |     100.00 |      73.33
       4 |      95.00 |     100.00 |      95.00 |      40.00
       5 |      88.00 |      92.00 |      84.00 |      52.00
       6 |     100.00 |      96.67 |      90.00 |      70.00
       7 |      94.29 |      88.57 |      97.14 |      62.86
       8 |      92.50 |      97.50 |      82.50 |      67.50
       9 |      73.33 |      75.56 |      71.11 |      55.56
      10 |      74.00 |      76.00 |      64.00 |      70.00
      11 |      81.82 |      92.73 |      80.00 |      67.27
      12 |      73.33 |      68.33 |      60.00 |      55.00
      13 |      63.08 |      81.54 |      43.08 |      52.31
      14 |      61.43 |      74.29 |      45.71 |      51.43
      15 |      49.33 |      66.67 |      32.00 |      58.67
----------------------------------------------------------------------
   Micro |      75.17 |      81.83 |      65.33 |      59.17
   Macro |      83.07 |      87.32 |      76.30 |      61.06
      EM |      53.33 |      58.67 |      46.67 |      14.67
======================================================================

그래프가 저장되었습니다: experiments/20251215_152914/accuracy_comparison.png
