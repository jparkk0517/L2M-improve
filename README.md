# L2M-improve

batch size : 20
LLM model : gpt-4o
words number : 1 -> 15
compare : baseline vs CoT vs L2M vs L2M-DV
![alt text](image.png)
