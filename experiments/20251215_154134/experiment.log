
======================================================================
num_words = 1 | batch_size = 5
Baseline | pred='s' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='s' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1

[Batch Summary for n_words=1]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 100.00%

======================================================================
num_words = 2 | batch_size = 5
Baseline | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='on' | pos_acc=1/2 (50.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='ms' | pos_acc=1/2 (50.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='ry' | pos_acc=1/2 (50.0%) | compared=2
Baseline | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='oc' | pos_acc=0/2 (0.0%) | compared=2

[Batch Summary for n_words=2]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 50.00%

======================================================================
num_words = 3 | batch_size = 5
Baseline | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='cne' | pos_acc=2/3 (66.7%) | compared=3
Baseline | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='eyt' | pos_acc=2/3 (66.7%) | compared=3

[Batch Summary for n_words=3]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 86.67%

======================================================================
num_words = 4 | batch_size = 5
Baseline | pred='myn' | pos_acc=3/4 (75.0%) | compared=3 | len_mismatch(gold=4, pred=3)
CoT      | pred='myny' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='myny' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='ryyn' | pos_acc=1/4 (25.0%) | compared=4
Baseline | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='y' | pos_acc=1/4 (25.0%) | compared=1 | len_mismatch(gold=4, pred=1)
Baseline | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ybye' | pos_acc=3/4 (75.0%) | compared=4
L2M-DV   | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
Baseline | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='nygn' | pos_acc=3/4 (75.0%) | compared=4
Baseline | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='tyee' | pos_acc=3/4 (75.0%) | compared=4

[Batch Summary for n_words=4]
  Baseline  : 95.00%
  CoT       : 100.00%
  L2M       : 95.00%
  L2M-DV    : 60.00%

======================================================================
num_words = 5 | batch_size = 5
Baseline | pred='xyyen' | pos_acc=3/5 (60.0%) | compared=5
CoT      | pred='yxyen' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='yxren' | pos_acc=4/5 (80.0%) | compared=5
L2M-DV   | pred='gxyen' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='ynync' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='enync' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='ynnsl' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='ynnsl' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='cnns' | pos_acc=3/5 (60.0%) | compared=4 | len_mismatch(gold=5, pred=4)
L2M-DV   | pred='tnnsn' | pos_acc=3/5 (60.0%) | compared=5
Baseline | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='enyyy' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='yyyyy' | pos_acc=4/5 (80.0%) | compared=5
CoT      | pred='yyyym' | pos_acc=3/5 (60.0%) | compared=5
L2M      | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='oymmy' | pos_acc=3/5 (60.0%) | compared=5

[Batch Summary for n_words=5]
  Baseline  : 88.00%
  CoT       : 92.00%
  L2M       : 88.00%
  L2M-DV    : 72.00%

======================================================================
num_words = 6 | batch_size = 5
Baseline | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nyeeyl' | pos_acc=5/6 (83.3%) | compared=6
L2M      | pred='nyeeyl' | pos_acc=5/6 (83.3%) | compared=6
L2M-DV   | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
Baseline | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='enyryl' | pos_acc=5/6 (83.3%) | compared=6
L2M-DV   | pred='rnymyl' | pos_acc=5/6 (83.3%) | compared=6
Baseline | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='y' | pos_acc=1/6 (16.7%) | compared=1 | len_mismatch(gold=6, pred=1)
Baseline | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
Baseline | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='nnnnyy' | pos_acc=5/6 (83.3%) | compared=6
L2M-DV   | pred='nnyeyy' | pos_acc=5/6 (83.3%) | compared=6

[Batch Summary for n_words=6]
  Baseline  : 100.00%
  CoT       : 96.67%
  L2M       : 90.00%
  L2M-DV    : 76.67%

======================================================================
num_words = 7 | batch_size = 5
Baseline | pred='yyyynny' | pos_acc=6/7 (85.7%) | compared=7
CoT      | pred='yyynnnn' | pos_acc=6/7 (85.7%) | compared=7
L2M      | pred='yyynnny' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='yyyyyyn' | pos_acc=3/7 (42.9%) | compared=7
Baseline | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
CoT      | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
L2M      | pred='nsmynyy' | pos_acc=6/7 (85.7%) | compared=7
L2M-DV   | pred='nsmnyny' | pos_acc=4/7 (57.1%) | compared=7
Baseline | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='snnnlyn' | pos_acc=4/7 (57.1%) | compared=7
Baseline | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='nynyyl' | pos_acc=4/7 (57.1%) | compared=6 | len_mismatch(gold=7, pred=6)
Baseline | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nyynyyy' | pos_acc=5/7 (71.4%) | compared=7
L2M-DV   | pred='eyyyny' | pos_acc=5/7 (71.4%) | compared=6 | len_mismatch(gold=7, pred=6)

[Batch Summary for n_words=7]
  Baseline  : 94.29%
  CoT       : 94.29%
  L2M       : 91.43%
  L2M-DV    : 57.14%

======================================================================
num_words = 8 | batch_size = 5
Baseline | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='tmsnyyey' | pos_acc=7/8 (87.5%) | compared=8
Baseline | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='yennsccn' | pos_acc=6/8 (75.0%) | compared=8
L2M-DV   | pred='lennnnscn' | pos_acc=4/8 (50.0%) | compared=8 | len_mismatch(gold=8, pred=9)
Baseline | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='nynneely' | pos_acc=6/8 (75.0%) | compared=8
L2M-DV   | pred='tynenely' | pos_acc=7/8 (87.5%) | compared=8
Baseline | pred='eyyyyyyn' | pos_acc=5/8 (62.5%) | compared=8
CoT      | pred='eyyyynny' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='eyyyynny' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='nyyyyyyy' | pos_acc=5/8 (62.5%) | compared=8
Baseline | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='yymynele' | pos_acc=7/8 (87.5%) | compared=8

[Batch Summary for n_words=8]
  Baseline  : 92.50%
  CoT       : 100.00%
  L2M       : 90.00%
  L2M-DV    : 75.00%

======================================================================
num_words = 9 | batch_size = 5
Baseline | pred='nyynlnnn' | pos_acc=5/9 (55.6%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nyyylnnnn' | pos_acc=7/9 (77.8%) | compared=9
L2M      | pred='nyynlnnn' | pos_acc=5/9 (55.6%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M-DV   | pred='eyynlnnn' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
Baseline | pred='nnnnnxy' | pos_acc=6/9 (66.7%) | compared=7 | len_mismatch(gold=9, pred=7)
CoT      | pred='nnnnnxy' | pos_acc=6/9 (66.7%) | compared=7 | len_mismatch(gold=9, pred=7)
L2M      | pred='nnnnnnxy' | pos_acc=6/9 (66.7%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M-DV   | pred='nnnnyxy' | pos_acc=5/9 (55.6%) | compared=7 | len_mismatch(gold=9, pred=7)
Baseline | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='nyyglgnyy' | pos_acc=4/9 (44.4%) | compared=9
Baseline | pred='nnelnexy' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nnenlenxy' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='nnelnexy' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
L2M-DV   | pred='enelnxy' | pos_acc=2/9 (22.2%) | compared=7 | len_mismatch(gold=9, pred=7)
Baseline | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='yymllnnny' | pos_acc=8/9 (88.9%) | compared=9

[Batch Summary for n_words=9]
  Baseline  : 73.33%
  CoT       : 88.89%
  L2M       : 73.33%
  L2M-DV    : 51.11%

======================================================================
num_words = 10 | batch_size = 5
Baseline | pred='nynyylmnen' | pos_acc=10/10 (100.0%) | compared=10
CoT      | pred='nynylmlnen' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nynynmnenn' | pos_acc=5/10 (50.0%) | compared=10
L2M-DV   | pred='nynyylmnen' | pos_acc=10/10 (100.0%) | compared=10
Baseline | pred='nnnyyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10 | len_mismatch(gold=10, pred=11)
CoT      | pred='nnnyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10
L2M      | pred='nnnyyyyyyy' | pos_acc=10/10 (100.0%) | compared=10
L2M-DV   | pred='nnnnnyyyyy' | pos_acc=8/10 (80.0%) | compared=10
Baseline | pred='nnsyneennl' | pos_acc=7/10 (70.0%) | compared=10
CoT      | pred='nnsyneennl' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nnsnynennl' | pos_acc=10/10 (100.0%) | compared=10
L2M-DV   | pred='nnsyennnl' | pos_acc=5/10 (50.0%) | compared=9 | len_mismatch(gold=10, pred=9)
Baseline | pred='neleenenymt' | pos_acc=7/10 (70.0%) | compared=10 | len_mismatch(gold=10, pred=11)
CoT      | pred='neleenymt' | pos_acc=6/10 (60.0%) | compared=9 | len_mismatch(gold=10, pred=9)
L2M      | pred='nelleeneymt' | pos_acc=4/10 (40.0%) | compared=10 | len_mismatch(gold=10, pred=11)
L2M-DV   | pred='negemneymt' | pos_acc=8/10 (80.0%) | compared=10
Baseline | pred='yymelynnxy' | pos_acc=6/10 (60.0%) | compared=10
CoT      | pred='yymeylnnyx' | pos_acc=10/10 (100.0%) | compared=10
L2M      | pred='yymeyynnyy' | pos_acc=8/10 (80.0%) | compared=10
L2M-DV   | pred='yymelynnxy' | pos_acc=6/10 (60.0%) | compared=10

[Batch Summary for n_words=10]
  Baseline  : 80.00%
  CoT       : 80.00%
  L2M       : 74.00%
  L2M-DV    : 74.00%

======================================================================
num_words = 11 | batch_size = 5
Baseline | pred='nyynmmyynle' | pos_acc=7/11 (63.6%) | compared=11
CoT      | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nynmynlye' | pos_acc=2/11 (18.2%) | compared=9 | len_mismatch(gold=11, pred=9)
L2M-DV   | pred='nymnyynlye' | pos_acc=4/11 (36.4%) | compared=10 | len_mismatch(gold=11, pred=10)
Baseline | pred='nnyssyltnmly' | pos_acc=4/11 (36.4%) | compared=11 | len_mismatch(gold=11, pred=12)
CoT      | pred='nnyslytnmny' | pos_acc=8/11 (72.7%) | compared=11
L2M      | pred='isoutputtedasfinalanswernnylytnmly' | pos_acc=0/11 (0.0%) | compared=11 | len_mismatch(gold=11, pred=34)
L2M-DV   | pred='nnysyltnmly' | pos_acc=11/11 (100.0%) | compared=11
Baseline | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
CoT      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nyecytmnnymy' | pos_acc=9/11 (81.8%) | compared=11 | len_mismatch(gold=11, pred=12)
Baseline | pred='mnlryymnnn' | pos_acc=8/11 (72.7%) | compared=10 | len_mismatch(gold=11, pred=10)
CoT      | pred='mnlyyyymnnn' | pos_acc=10/11 (90.9%) | compared=11
L2M      | pred='mnlryyymnn' | pos_acc=10/11 (90.9%) | compared=10 | len_mismatch(gold=11, pred=10)
L2M-DV   | pred='mnlyyyyynnn' | pos_acc=9/11 (81.8%) | compared=11
Baseline | pred='yyenynncen' | pos_acc=5/11 (45.5%) | compared=10 | len_mismatch(gold=11, pred=10)
CoT      | pred='yyennynncen' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='yyenngnncen' | pos_acc=10/11 (90.9%) | compared=11
L2M-DV   | pred='yynnnyncen' | pos_acc=6/11 (54.5%) | compared=10 | len_mismatch(gold=11, pred=10)

[Batch Summary for n_words=11]
  Baseline  : 63.64%
  CoT       : 92.73%
  L2M       : 60.00%
  L2M-DV    : 70.91%

======================================================================
num_words = 12 | batch_size = 5
Baseline | pred='nsnylynyyn' | pos_acc=10/12 (83.3%) | compared=10 | len_mismatch(gold=12, pred=10)
CoT      | pred='nsnylynyyny' | pos_acc=10/12 (83.3%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='nsnylynyyn' | pos_acc=10/12 (83.3%) | compared=10 | len_mismatch(gold=12, pred=10)
L2M-DV   | pred='nsnlynyynny' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='yeycltnnnlnn' | pos_acc=12/12 (100.0%) | compared=12
L2M      | pred='yeycltnnlnn' | pos_acc=9/12 (75.0%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='yeycltnnnln' | pos_acc=11/12 (91.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='enynysgynen' | pos_acc=6/12 (50.0%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='enyynysgnyn' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='enynyysgyen' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='enynyygsnyn' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='eyynyyyyynmn' | pos_acc=9/12 (75.0%) | compared=12
CoT      | pred='eyynnnyynmmn' | pos_acc=6/12 (50.0%) | compared=12
L2M      | pred='eyennnnnnnnnn' | pos_acc=5/12 (41.7%) | compared=12 | len_mismatch(gold=12, pred=13)
L2M-DV   | pred='eennnnyylm' | pos_acc=4/12 (33.3%) | compared=10 | len_mismatch(gold=12, pred=10)
Baseline | pred='ynynnnymrye' | pos_acc=5/12 (41.7%) | compared=11 | len_mismatch(gold=12, pred=11)
CoT      | pred='ynynnynmrye' | pos_acc=4/12 (33.3%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M      | pred='ynynlynmrye' | pos_acc=3/12 (25.0%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='ynynlnmrye' | pos_acc=3/12 (25.0%) | compared=10 | len_mismatch(gold=12, pred=10)

[Batch Summary for n_words=12]
  Baseline  : 68.33%
  CoT       : 66.67%
  L2M       : 58.33%
  L2M-DV    : 51.67%

======================================================================
num_words = 13 | batch_size = 5
Baseline | pred='ynynnnylynnny' | pos_acc=9/13 (69.2%) | compared=13
CoT      | pred='ynynyyylnyny' | pos_acc=6/13 (46.2%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M      | pred='ynynnyyylnny' | pos_acc=10/13 (76.9%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='ynynnyylynnyy' | pos_acc=9/13 (69.2%) | compared=13
Baseline | pred='nycgnynyyecnl' | pos_acc=13/13 (100.0%) | compared=13
CoT      | pred='nycgnynyyecn' | pos_acc=12/13 (92.3%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M      | pred='nycgnynyyecnl' | pos_acc=13/13 (100.0%) | compared=13
L2M-DV   | pred='sycgnynycln' | pos_acc=7/13 (53.8%) | compared=11 | len_mismatch(gold=13, pred=11)
Baseline | pred='nnynnnneyml' | pos_acc=8/13 (61.5%) | compared=11 | len_mismatch(gold=13, pred=11)
CoT      | pred='nnynnnnnnnmly' | pos_acc=10/13 (76.9%) | compared=13
L2M      | pred='nnnnionnnnna' | pos_acc=4/13 (30.8%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='nnyynnnemly' | pos_acc=7/13 (53.8%) | compared=11 | len_mismatch(gold=13, pred=11)
Baseline | pred='ynnsrlnnnngyl' | pos_acc=13/13 (100.0%) | compared=13
CoT      | pred='ynnsrlnnngyl' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M      | pred='otnedtdednss' | pos_acc=2/13 (15.4%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='ynnsrlnnnlgyl' | pos_acc=12/13 (92.3%) | compared=13
Baseline | pred='nlnnynely' | pos_acc=6/13 (46.2%) | compared=9 | len_mismatch(gold=13, pred=9)
CoT      | pred='nlnnynnyly' | pos_acc=6/13 (46.2%) | compared=10 | len_mismatch(gold=13, pred=10)
L2M      | pred='nlnnyynyenyl' | pos_acc=9/13 (69.2%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='nlnynynely' | pos_acc=3/13 (23.1%) | compared=10 | len_mismatch(gold=13, pred=10)

[Batch Summary for n_words=13]
  Baseline  : 75.38%
  CoT       : 66.15%
  L2M       : 58.46%
  L2M-DV    : 58.46%

======================================================================
num_words = 14 | batch_size = 5
Baseline | pred='nnslnnnnnnml' | pos_acc=7/14 (50.0%) | compared=12 | len_mismatch(gold=14, pred=12)
CoT      | pred='nnnslnnnnnml' | pos_acc=10/14 (71.4%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M      | pred='nnnslnnnnnml' | pos_acc=10/14 (71.4%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M-DV   | pred='nnnslnnnnnml' | pos_acc=10/14 (71.4%) | compared=12 | len_mismatch(gold=14, pred=12)
Baseline | pred='lenynellyyey' | pos_acc=10/14 (71.4%) | compared=12 | len_mismatch(gold=14, pred=12)
CoT      | pred='lenyneelyylyey' | pos_acc=14/14 (100.0%) | compared=14
L2M      | pred='lenynelilye' | pos_acc=7/14 (50.0%) | compared=11 | len_mismatch(gold=14, pred=11)
L2M-DV   | pred='lenynelylyey' | pos_acc=8/14 (57.1%) | compared=12 | len_mismatch(gold=14, pred=12)
Baseline | pred='nynynennyynyt' | pos_acc=10/14 (71.4%) | compared=13 | len_mismatch(gold=14, pred=13)
CoT      | pred='nyynynnnnyyn' | pos_acc=8/14 (57.1%) | compared=12 | len_mismatch(gold=14, pred=12)
L2M      | pred='nyyynnnnnnnnnnn' | pos_acc=7/14 (50.0%) | compared=14 | len_mismatch(gold=14, pred=15)
L2M-DV   | pred='nynyenyynynyn' | pos_acc=5/14 (35.7%) | compared=13 | len_mismatch(gold=14, pred=13)
Baseline | pred='lynnlynnyny' | pos_acc=5/14 (35.7%) | compared=11 | len_mismatch(gold=14, pred=11)
CoT      | pred='lyynnnlnyyyny' | pos_acc=10/14 (71.4%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M      | pred='onmllnniiiiii' | pos_acc=1/14 (7.1%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='nyyynnlnnyynny' | pos_acc=9/14 (64.3%) | compared=14
Baseline | pred='lynncnsslnnnnn' | pos_acc=12/14 (85.7%) | compared=14
CoT      | pred='lynncnsslnnnnn' | pos_acc=12/14 (85.7%) | compared=14
L2M      | pred='lynnztnnllnlln' | pos_acc=7/14 (50.0%) | compared=14
L2M-DV   | pred='nynncnsslnnnnn' | pos_acc=11/14 (78.6%) | compared=14

[Batch Summary for n_words=14]
  Baseline  : 62.86%
  CoT       : 77.14%
  L2M       : 45.71%
  L2M-DV    : 61.43%

======================================================================
num_words = 15 | batch_size = 5
Baseline | pred='ymyyyyyenmenyyyy' | pos_acc=14/15 (93.3%) | compared=15 | len_mismatch(gold=15, pred=16)
CoT      | pred='ymyyyyyneemnnyy' | pos_acc=9/15 (60.0%) | compared=15
L2M      | pred='ysmnlycaytyycyi' | pos_acc=2/15 (13.3%) | compared=15
L2M-DV   | pred='ymynynemnyyyyy' | pos_acc=8/15 (53.3%) | compared=14 | len_mismatch(gold=15, pred=14)
Baseline | pred='yynelynyncnny' | pos_acc=7/15 (46.7%) | compared=13 | len_mismatch(gold=15, pred=13)
CoT      | pred='yyneyleycnyyn' | pos_acc=8/15 (53.3%) | compared=13 | len_mismatch(gold=15, pred=13)
L2M      | pred='ynelylencynyc' | pos_acc=5/15 (33.3%) | compared=13 | len_mismatch(gold=15, pred=13)
L2M-DV   | pred='yynelylnyncnyn' | pos_acc=6/15 (40.0%) | compared=14 | len_mismatch(gold=15, pred=14)
Baseline | pred='mynnyysyenelty' | pos_acc=4/15 (26.7%) | compared=14 | len_mismatch(gold=15, pred=14)
CoT      | pred='mynnyysyenelty' | pos_acc=4/15 (26.7%) | compared=14 | len_mismatch(gold=15, pred=14)
L2M      | pred='smnonnllyeeycsy' | pos_acc=5/15 (33.3%) | compared=15
L2M-DV   | pred='mynnnyysyenlty' | pos_acc=10/15 (66.7%) | compared=14 | len_mismatch(gold=15, pred=14)
Baseline | pred='eeysnynnyynny' | pos_acc=13/15 (86.7%) | compared=13 | len_mismatch(gold=15, pred=13)
CoT      | pred='eeysnynnyynny' | pos_acc=13/15 (86.7%) | compared=13 | len_mismatch(gold=15, pred=13)
L2M      | pred='eeeeyyiyyiyyyy' | pos_acc=5/15 (33.3%) | compared=14 | len_mismatch(gold=15, pred=14)
L2M-DV   | pred='eeysnynnyynnyy' | pos_acc=13/15 (86.7%) | compared=14 | len_mismatch(gold=15, pred=14)
Baseline | pred='nnnneyynnnlyen' | pos_acc=10/15 (66.7%) | compared=14 | len_mismatch(gold=15, pred=14)
CoT      | pred='nnnneyynnyllnen' | pos_acc=15/15 (100.0%) | compared=15
L2M      | pred='ononononononon' | pos_acc=3/15 (20.0%) | compared=14 | len_mismatch(gold=15, pred=14)
L2M-DV   | pred='nnyynnylne' | pos_acc=4/15 (26.7%) | compared=10 | len_mismatch(gold=15, pred=10)

[Batch Summary for n_words=15]
  Baseline  : 64.00%
  CoT       : 65.33%
  L2M       : 26.67%
  L2M-DV    : 54.67%
----------------------------------------------------------------------
Average position-wise accuracy (Macro / Micro) | Exact Match
Baseline : 83.82% / 76.83% | EM: 53.33%
CoT      : 87.99% / 82.00% | EM: 62.67%
L2M      : 76.73% / 65.67% | EM: 48.00%
L2M-DV   : 66.65% / 63.00% | EM: 18.67%

======================================================================
Position-wise Accuracy by Number of Words (%)
======================================================================
 n_words |   Baseline |        CoT |        L2M |     L2M-DV
----------------------------------------------------------------------
       1 |     100.00 |     100.00 |     100.00 |     100.00
       2 |     100.00 |     100.00 |     100.00 |      50.00
       3 |     100.00 |     100.00 |     100.00 |      86.67
       4 |      95.00 |     100.00 |      95.00 |      60.00
       5 |      88.00 |      92.00 |      88.00 |      72.00
       6 |     100.00 |      96.67 |      90.00 |      76.67
       7 |      94.29 |      94.29 |      91.43 |      57.14
       8 |      92.50 |     100.00 |      90.00 |      75.00
       9 |      73.33 |      88.89 |      73.33 |      51.11
      10 |      80.00 |      80.00 |      74.00 |      74.00
      11 |      63.64 |      92.73 |      60.00 |      70.91
      12 |      68.33 |      66.67 |      58.33 |      51.67
      13 |      75.38 |      66.15 |      58.46 |      58.46
      14 |      62.86 |      77.14 |      45.71 |      61.43
      15 |      64.00 |      65.33 |      26.67 |      54.67
----------------------------------------------------------------------
   Micro |      76.83 |      82.00 |      65.67 |      63.00
   Macro |      83.82 |      87.99 |      76.73 |      66.65
      EM |      53.33 |      62.67 |      48.00 |      18.67
======================================================================

그래프가 저장되었습니다: experiments/20251215_154134/accuracy_comparison.png
