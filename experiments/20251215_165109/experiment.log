
======================================================================
num_words = 1 | batch_size = 5
Baseline | pred='s' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='s' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='s' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=0/1 (0.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='l' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='l' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='l' | pos_acc=1/1 (100.0%) | compared=1
Baseline | pred='y' | pos_acc=1/1 (100.0%) | compared=1
CoT      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M      | pred='y' | pos_acc=1/1 (100.0%) | compared=1
L2M-DV   | pred='y' | pos_acc=1/1 (100.0%) | compared=1

[Batch Summary for n_words=1]
  Baseline  : 100.00%
  CoT       : 80.00%
  L2M       : 100.00%
  L2M-DV    : 100.00%

======================================================================
num_words = 2 | batch_size = 5
Baseline | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='yt' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='nn' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='my' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='my' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='my' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='my' | pos_acc=2/2 (100.0%) | compared=2
Baseline | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
CoT      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M      | pred='yn' | pos_acc=2/2 (100.0%) | compared=2
L2M-DV   | pred='yn' | pos_acc=2/2 (100.0%) | compared=2

[Batch Summary for n_words=2]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 100.00%

======================================================================
num_words = 3 | batch_size = 5
Baseline | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='snn' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='yne' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='nnn' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='nln' | pos_acc=2/3 (66.7%) | compared=3
Baseline | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='yen' | pos_acc=3/3 (100.0%) | compared=3
Baseline | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
CoT      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M      | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3
L2M-DV   | pred='yyt' | pos_acc=3/3 (100.0%) | compared=3

[Batch Summary for n_words=3]
  Baseline  : 100.00%
  CoT       : 100.00%
  L2M       : 100.00%
  L2M-DV    : 93.33%

======================================================================
num_words = 4 | batch_size = 5
Baseline | pred='lyny' | pos_acc=3/4 (75.0%) | compared=4
CoT      | pred='lyny' | pos_acc=3/4 (75.0%) | compared=4
L2M      | pred='mlny' | pos_acc=3/4 (75.0%) | compared=4
L2M-DV   | pred='myny' | pos_acc=4/4 (100.0%) | compared=4
Baseline | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='ymrn' | pos_acc=4/4 (100.0%) | compared=4
Baseline | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='yyye' | pos_acc=4/4 (100.0%) | compared=4
Baseline | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M      | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='yygn' | pos_acc=4/4 (100.0%) | compared=4
Baseline | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
CoT      | pred='ryet' | pos_acc=3/4 (75.0%) | compared=4
L2M      | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4
L2M-DV   | pred='ryee' | pos_acc=4/4 (100.0%) | compared=4

[Batch Summary for n_words=4]
  Baseline  : 95.00%
  CoT       : 90.00%
  L2M       : 95.00%
  L2M-DV    : 100.00%

======================================================================
num_words = 5 | batch_size = 5
Baseline | pred='yxyen' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='yxlen' | pos_acc=4/5 (80.0%) | compared=5
L2M      | pred='yxyen' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='yxlen' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='ynytc' | pos_acc=4/5 (80.0%) | compared=5
CoT      | pred='ynytc' | pos_acc=4/5 (80.0%) | compared=5
L2M      | pred='ynytc' | pos_acc=4/5 (80.0%) | compared=5
L2M-DV   | pred='ynytc' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='snntl' | pos_acc=3/5 (60.0%) | compared=5
CoT      | pred='snntl' | pos_acc=3/5 (60.0%) | compared=5
L2M      | pred='ynnsl' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='ynntl' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='nnyyy' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='nnyyt' | pos_acc=4/5 (80.0%) | compared=5
L2M      | pred='nnnyy' | pos_acc=4/5 (80.0%) | compared=5
L2M-DV   | pred='nnlyy' | pos_acc=4/5 (80.0%) | compared=5
Baseline | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5
CoT      | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5
L2M      | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5
L2M-DV   | pred='yyymy' | pos_acc=5/5 (100.0%) | compared=5

[Batch Summary for n_words=5]
  Baseline  : 88.00%
  CoT       : 80.00%
  L2M       : 92.00%
  L2M-DV    : 84.00%

======================================================================
num_words = 6 | batch_size = 5
Baseline | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nyeyll' | pos_acc=5/6 (83.3%) | compared=6
L2M      | pred='nyeyyl' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='nyeyll' | pos_acc=5/6 (83.3%) | compared=6
Baseline | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='enymyl' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='enyyml' | pos_acc=4/6 (66.7%) | compared=6
L2M-DV   | pred='enyml' | pos_acc=4/6 (66.7%) | compared=5 | len_mismatch(gold=6, pred=5)
Baseline | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='ymnnyy' | pos_acc=6/6 (100.0%) | compared=6
Baseline | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='ynlmyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='ynrmyy' | pos_acc=5/6 (83.3%) | compared=6
Baseline | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
CoT      | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
L2M      | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6
L2M-DV   | pred='nnneyy' | pos_acc=6/6 (100.0%) | compared=6

[Batch Summary for n_words=6]
  Baseline  : 100.00%
  CoT       : 96.67%
  L2M       : 93.33%
  L2M-DV    : 86.67%

======================================================================
num_words = 7 | batch_size = 5
Baseline | pred='nsmlyyy' | pos_acc=5/7 (71.4%) | compared=7
CoT      | pred='nsmylyy' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nsmylyy' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='nsmylyy' | pos_acc=7/7 (100.0%) | compared=7
Baseline | pred='yyynnny' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='yyynnny' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='yyylnny' | pos_acc=6/7 (85.7%) | compared=7
L2M-DV   | pred='ylynnny' | pos_acc=6/7 (85.7%) | compared=7
Baseline | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='mnnnlynandnothingelse' | pos_acc=5/7 (71.4%) | compared=7 | len_mismatch(gold=7, pred=21)
L2M-DV   | pred='mnnnyln' | pos_acc=7/7 (100.0%) | compared=7
Baseline | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
CoT      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
L2M-DV   | pred='nynysyl' | pos_acc=7/7 (100.0%) | compared=7
Baseline | pred='nyyyyny' | pos_acc=5/7 (71.4%) | compared=7
CoT      | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7
L2M      | pred='nylynyy' | pos_acc=6/7 (85.7%) | compared=7
L2M-DV   | pred='nyyynyy' | pos_acc=7/7 (100.0%) | compared=7

[Batch Summary for n_words=7]
  Baseline  : 88.57%
  CoT       : 100.00%
  L2M       : 88.57%
  L2M-DV    : 97.14%

======================================================================
num_words = 8 | batch_size = 5
Baseline | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='yennnscn' | pos_acc=8/8 (100.0%) | compared=8
Baseline | pred='nmsnyyet' | pos_acc=7/8 (87.5%) | compared=8
CoT      | pred='nmsnyeyey' | pos_acc=5/8 (62.5%) | compared=8 | len_mismatch(gold=8, pred=9)
L2M      | pred='nmsnyyey' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='nmsnyeye' | pos_acc=5/8 (62.5%) | compared=8
Baseline | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
CoT      | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='nyoenely' | pos_acc=7/8 (87.5%) | compared=8
L2M-DV   | pred='nynenely' | pos_acc=8/8 (100.0%) | compared=8
Baseline | pred='eyyyynne' | pos_acc=7/8 (87.5%) | compared=8
CoT      | pred='eyyyynne' | pos_acc=7/8 (87.5%) | compared=8
L2M      | pred='eyhyynne' | pos_acc=6/8 (75.0%) | compared=8
L2M-DV   | pred='eyyyynne' | pos_acc=7/8 (87.5%) | compared=8
Baseline | pred='yymynele' | pos_acc=7/8 (87.5%) | compared=8
CoT      | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
L2M      | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8
L2M-DV   | pred='ynmynele' | pos_acc=8/8 (100.0%) | compared=8

[Batch Summary for n_words=8]
  Baseline  : 92.50%
  CoT       : 90.00%
  L2M       : 92.50%
  L2M-DV    : 90.00%

======================================================================
num_words = 9 | batch_size = 5
Baseline | pred='nyyynlnnn' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='nyyylnnnn' | pos_acc=7/9 (77.8%) | compared=9
L2M      | pred='nyyynlnnn' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='nyyylnnnn' | pos_acc=7/9 (77.8%) | compared=9
Baseline | pred='nnrnnnyxe' | pos_acc=7/9 (77.8%) | compared=9
CoT      | pred='nttnnnyxe' | pos_acc=6/9 (66.7%) | compared=9
L2M      | pred='nttnnnyxe' | pos_acc=6/9 (66.7%) | compared=9
L2M-DV   | pred='nntnnnyxe' | pos_acc=7/9 (77.8%) | compared=9
Baseline | pred='tyylgnyny' | pos_acc=8/9 (88.9%) | compared=9
CoT      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='nyylgnyny' | pos_acc=9/9 (100.0%) | compared=9
Baseline | pred='nnleneny' | pos_acc=4/9 (44.4%) | compared=8 | len_mismatch(gold=9, pred=8)
CoT      | pred='nnenlenxy' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='nnenlenxy' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='nnenlenxy' | pos_acc=9/9 (100.0%) | compared=9
Baseline | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
CoT      | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
L2M      | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9
L2M-DV   | pred='yymlnnnny' | pos_acc=9/9 (100.0%) | compared=9

[Batch Summary for n_words=9]
  Baseline  : 82.22%
  CoT       : 88.89%
  L2M       : 93.33%
  L2M-DV    : 91.11%

======================================================================
num_words = 10 | batch_size = 5
Baseline | pred='nenlylmnen' | pos_acc=8/10 (80.0%) | compared=10
CoT      | pred='nenyylmnen' | pos_acc=9/10 (90.0%) | compared=10
L2M      | pred='nenlylmren' | pos_acc=7/10 (70.0%) | compared=10
L2M-DV   | pred='nenyylmnen' | pos_acc=9/10 (90.0%) | compared=10
Baseline | pred='nnnyyyyeyy' | pos_acc=9/10 (90.0%) | compared=10
CoT      | pred='nnnyyyyeyy' | pos_acc=9/10 (90.0%) | compared=10
L2M      | pred='nnnyyyyeyy' | pos_acc=9/10 (90.0%) | compared=10
L2M-DV   | pred='nnnyyyyeyy' | pos_acc=9/10 (90.0%) | compared=10
Baseline | pred='nnsnynennl' | pos_acc=10/10 (100.0%) | compared=10
CoT      | pred='nnsynyennl' | pos_acc=7/10 (70.0%) | compared=10
L2M      | pred='nnsnynennl' | pos_acc=10/10 (100.0%) | compared=10
L2M-DV   | pred='lnsynyennl' | pos_acc=6/10 (60.0%) | compared=10
Baseline | pred='teleeneymt' | pos_acc=9/10 (90.0%) | compared=10
CoT      | pred='teleeneymt' | pos_acc=9/10 (90.0%) | compared=10
L2M      | pred='teleeneymt' | pos_acc=9/10 (90.0%) | compared=10
L2M-DV   | pred='neleeneymt' | pos_acc=10/10 (100.0%) | compared=10
Baseline | pred='yymeylnnxy' | pos_acc=8/10 (80.0%) | compared=10
CoT      | pred='yymeylnnxy' | pos_acc=8/10 (80.0%) | compared=10
L2M      | pred='yymeylnnxy' | pos_acc=8/10 (80.0%) | compared=10
L2M-DV   | pred='yymeylnnxy' | pos_acc=8/10 (80.0%) | compared=10

[Batch Summary for n_words=10]
  Baseline  : 88.00%
  CoT       : 84.00%
  L2M       : 86.00%
  L2M-DV    : 84.00%

======================================================================
num_words = 11 | batch_size = 5
Baseline | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
CoT      | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nyynmyynlye' | pos_acc=11/11 (100.0%) | compared=11
Baseline | pred='nnysyltnmly' | pos_acc=11/11 (100.0%) | compared=11
CoT      | pred='nnysyltnmly' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nnysyltnmly' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nnysyltnmly' | pos_acc=11/11 (100.0%) | compared=11
Baseline | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
CoT      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M      | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
L2M-DV   | pred='nyecytmnnmy' | pos_acc=11/11 (100.0%) | compared=11
Baseline | pred='lnlryyymnnn' | pos_acc=10/11 (90.9%) | compared=11
CoT      | pred='lnlryyymnnn' | pos_acc=10/11 (90.9%) | compared=11
L2M      | pred='mnlyyyymnnn' | pos_acc=10/11 (90.9%) | compared=11
L2M-DV   | pred='mnlyyyymnnn' | pos_acc=10/11 (90.9%) | compared=11
Baseline | pred='yyennyntcen' | pos_acc=10/11 (90.9%) | compared=11
CoT      | pred='yyennyntcen' | pos_acc=10/11 (90.9%) | compared=11
L2M      | pred='yyennyntcen' | pos_acc=10/11 (90.9%) | compared=11
L2M-DV   | pred='yyennyntcen' | pos_acc=10/11 (90.9%) | compared=11

[Batch Summary for n_words=11]
  Baseline  : 96.36%
  CoT       : 96.36%
  L2M       : 96.36%
  L2M-DV    : 96.36%

======================================================================
num_words = 12 | batch_size = 5
Baseline | pred='yeyclttnnlnn' | pos_acc=11/12 (91.7%) | compared=12
CoT      | pred='yeyclttnnlnn' | pos_acc=11/12 (91.7%) | compared=12
L2M      | pred='yeycltrnnlnn' | pos_acc=11/12 (91.7%) | compared=12
L2M-DV   | pred='yeycltnnnlnn' | pos_acc=12/12 (100.0%) | compared=12
Baseline | pred='nslylynnynny' | pos_acc=10/12 (83.3%) | compared=12
CoT      | pred='nsnylynyynny' | pos_acc=12/12 (100.0%) | compared=12
L2M      | pred='nsnylynyynny' | pos_acc=12/12 (100.0%) | compared=12
L2M-DV   | pred='nsnylynyynny' | pos_acc=12/12 (100.0%) | compared=12
Baseline | pred='enynyysgnyen' | pos_acc=12/12 (100.0%) | compared=12
CoT      | pred='enynyysgnyen' | pos_acc=12/12 (100.0%) | compared=12
L2M      | pred='enynyysgnyen' | pos_acc=12/12 (100.0%) | compared=12
L2M-DV   | pred='enynyysgnyen' | pos_acc=12/12 (100.0%) | compared=12
Baseline | pred='eynnnyyylmnmn' | pos_acc=6/12 (50.0%) | compared=12 | len_mismatch(gold=12, pred=13)
CoT      | pred='eynnyyylmnmn' | pos_acc=12/12 (100.0%) | compared=12
L2M      | pred='eynnyylmnmn' | pos_acc=6/12 (50.0%) | compared=11 | len_mismatch(gold=12, pred=11)
L2M-DV   | pred='eynnyyylnmn' | pos_acc=8/12 (66.7%) | compared=11 | len_mismatch(gold=12, pred=11)
Baseline | pred='ynyynlynmrye' | pos_acc=12/12 (100.0%) | compared=12
CoT      | pred='ynyynlynmrye' | pos_acc=12/12 (100.0%) | compared=12
L2M      | pred='ynyynlynmrye' | pos_acc=12/12 (100.0%) | compared=12
L2M-DV   | pred='ynyynlynmrye' | pos_acc=12/12 (100.0%) | compared=12

[Batch Summary for n_words=12]
  Baseline  : 85.00%
  CoT       : 98.33%
  L2M       : 88.33%
  L2M-DV    : 93.33%

======================================================================
num_words = 13 | batch_size = 5
Baseline | pred='ynytnyyelnsny' | pos_acc=10/13 (76.9%) | compared=13
CoT      | pred='ynytnyyylnyny' | pos_acc=12/13 (92.3%) | compared=13
L2M      | pred='ynytnyyylyny' | pos_acc=8/13 (61.5%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='ynytnyyylnyny' | pos_acc=12/13 (92.3%) | compared=13
Baseline | pred='nycgnlyyectl' | pos_acc=6/13 (46.2%) | compared=12 | len_mismatch(gold=13, pred=12)
CoT      | pred='nycgnlnyyectl' | pos_acc=11/13 (84.6%) | compared=13
L2M      | pred='tycglnnyyectl' | pos_acc=9/13 (69.2%) | compared=13
L2M-DV   | pred='nycgnlnyyectl' | pos_acc=11/13 (84.6%) | compared=13
Baseline | pred='nnynnnneeymls' | pos_acc=12/13 (92.3%) | compared=13
CoT      | pred='nnynnnneeymls' | pos_acc=12/13 (92.3%) | compared=13
L2M      | pred='nnynnnneeymly' | pos_acc=13/13 (100.0%) | compared=13
L2M-DV   | pred='nnynnnneeymls' | pos_acc=12/13 (92.3%) | compared=13
Baseline | pred='ynnsrlnnnngyr' | pos_acc=12/13 (92.3%) | compared=13
CoT      | pred='ynnsrlnnnngry' | pos_acc=11/13 (84.6%) | compared=13
L2M      | pred='ynnsrlnnnngyr' | pos_acc=12/13 (92.3%) | compared=13
L2M-DV   | pred='ynnsrlnnnngyr' | pos_acc=12/13 (92.3%) | compared=13
Baseline | pred='nlnnnynyenyly' | pos_acc=9/13 (69.2%) | compared=13
CoT      | pred='nlnynynnenyly' | pos_acc=9/13 (69.2%) | compared=13
L2M      | pred='nlnnynyenely' | pos_acc=7/13 (53.8%) | compared=12 | len_mismatch(gold=13, pred=12)
L2M-DV   | pred='nlnnynyenlyy' | pos_acc=8/13 (61.5%) | compared=12 | len_mismatch(gold=13, pred=12)

[Batch Summary for n_words=13]
  Baseline  : 75.38%
  CoT       : 84.62%
  L2M       : 75.38%
  L2M-DV    : 84.62%

======================================================================
num_words = 14 | batch_size = 5
Baseline | pred='nnnslntnnnnnml' | pos_acc=13/14 (92.9%) | compared=14
CoT      | pred='nnnslnnnnnnnml' | pos_acc=14/14 (100.0%) | compared=14
L2M      | pred='nnnslnnnnnnnml' | pos_acc=14/14 (100.0%) | compared=14
L2M-DV   | pred='nnnslnnnnnnnml' | pos_acc=14/14 (100.0%) | compared=14
Baseline | pred='lenyneelyyley' | pos_acc=11/14 (78.6%) | compared=13 | len_mismatch(gold=14, pred=13)
CoT      | pred='lenyneelylyey' | pos_acc=9/14 (64.3%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M      | pred='lenyneelyyley' | pos_acc=11/14 (78.6%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='lenyoeeleylyely' | pos_acc=11/14 (78.6%) | compared=14 | len_mismatch(gold=14, pred=15)
Baseline | pred='nyynnennyten' | pos_acc=8/14 (57.1%) | compared=12 | len_mismatch(gold=14, pred=12)
CoT      | pred='nyynyennyyntn' | pos_acc=11/14 (78.6%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M      | pred='nyynyennyyntn' | pos_acc=11/14 (78.6%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='nyynyennyyntn' | pos_acc=11/14 (78.6%) | compared=13 | len_mismatch(gold=14, pred=13)
Baseline | pred='llynntlnyynynn' | pos_acc=11/14 (78.6%) | compared=14
CoT      | pred='llynntlnyynynn' | pos_acc=11/14 (78.6%) | compared=14
L2M      | pred='lyynnlnyynyny' | pos_acc=6/14 (42.9%) | compared=13 | len_mismatch(gold=14, pred=13)
L2M-DV   | pred='llynntlnyynyry' | pos_acc=11/14 (78.6%) | compared=14
Baseline | pred='lynnncsslnnnnn' | pos_acc=14/14 (100.0%) | compared=14
CoT      | pred='lynnncsslnnnnn' | pos_acc=14/14 (100.0%) | compared=14
L2M      | pred='lynncsslnnnnnn' | pos_acc=10/14 (71.4%) | compared=14
L2M-DV   | pred='lyynnctslnnnnn' | pos_acc=12/14 (85.7%) | compared=14

[Batch Summary for n_words=14]
  Baseline  : 81.43%
  CoT       : 84.29%
  L2M       : 74.29%
  L2M-DV    : 84.29%

======================================================================
num_words = 15 | batch_size = 5
Baseline | pred='ymlyynyenmenyyy' | pos_acc=14/15 (93.3%) | compared=15
CoT      | pred='ymlyynyenmenyyy' | pos_acc=14/15 (93.3%) | compared=15
L2M      | pred='ymlyynyenmenyyy' | pos_acc=14/15 (93.3%) | compared=15
L2M-DV   | pred='ymyyynyenmenyyy' | pos_acc=15/15 (100.0%) | compared=15
Baseline | pred='yyneyleanycnlyn' | pos_acc=14/15 (93.3%) | compared=15
CoT      | pred='yyneyleanycnlyn' | pos_acc=14/15 (93.3%) | compared=15
L2M      | pred='yynesyeanycnlyn' | pos_acc=12/15 (80.0%) | compared=15
L2M-DV   | pred='yyneyyeanycnlyn' | pos_acc=13/15 (86.7%) | compared=15
Baseline | pred='mynlnsyeseenelty' | pos_acc=7/15 (46.7%) | compared=15 | len_mismatch(gold=15, pred=16)
CoT      | pred='mynlnsyesenelty' | pos_acc=12/15 (80.0%) | compared=15
L2M      | pred='mynlnsyesenelty' | pos_acc=12/15 (80.0%) | compared=15
L2M-DV   | pred='mynlnyyeseenelty' | pos_acc=8/15 (53.3%) | compared=15 | len_mismatch(gold=15, pred=16)
Baseline | pred='eeysnynnyynnyty' | pos_acc=14/15 (93.3%) | compared=15
CoT      | pred='eeysnynnynnntyy' | pos_acc=12/15 (80.0%) | compared=15
L2M      | pred='eeysnynnyynnntyy' | pos_acc=13/15 (86.7%) | compared=15 | len_mismatch(gold=15, pred=16)
L2M-DV   | pred='eeysnynnyynnnty' | pos_acc=13/15 (86.7%) | compared=15
Baseline | pred='nnnneyynnsllnen' | pos_acc=14/15 (93.3%) | compared=15
CoT      | pred='nnnneyynnyllnen' | pos_acc=15/15 (100.0%) | compared=15
L2M      | pred='nnnleyynnyllnen' | pos_acc=14/15 (93.3%) | compared=15
L2M-DV   | pred='nnnleyynnllnen' | pos_acc=9/15 (60.0%) | compared=14 | len_mismatch(gold=15, pred=14)

[Batch Summary for n_words=15]
  Baseline  : 84.00%
  CoT       : 89.33%
  L2M       : 86.67%
  L2M-DV    : 77.33%
----------------------------------------------------------------------
Average position-wise accuracy (Macro / Micro) | Exact Match
Baseline : 90.43% / 87.17% | EM: 54.67%
CoT      : 90.83% / 90.33% | EM: 57.33%
L2M      : 90.78% / 87.50% | EM: 58.67%
L2M-DV   : 90.81% / 88.33% | EM: 56.00%

======================================================================
Position-wise Accuracy by Number of Words (%)
======================================================================
 n_words |   Baseline |        CoT |        L2M |     L2M-DV
----------------------------------------------------------------------
       1 |     100.00 |      80.00 |     100.00 |     100.00
       2 |     100.00 |     100.00 |     100.00 |     100.00
       3 |     100.00 |     100.00 |     100.00 |      93.33
       4 |      95.00 |      90.00 |      95.00 |     100.00
       5 |      88.00 |      80.00 |      92.00 |      84.00
       6 |     100.00 |      96.67 |      93.33 |      86.67
       7 |      88.57 |     100.00 |      88.57 |      97.14
       8 |      92.50 |      90.00 |      92.50 |      90.00
       9 |      82.22 |      88.89 |      93.33 |      91.11
      10 |      88.00 |      84.00 |      86.00 |      84.00
      11 |      96.36 |      96.36 |      96.36 |      96.36
      12 |      85.00 |      98.33 |      88.33 |      93.33
      13 |      75.38 |      84.62 |      75.38 |      84.62
      14 |      81.43 |      84.29 |      74.29 |      84.29
      15 |      84.00 |      89.33 |      86.67 |      77.33
----------------------------------------------------------------------
   Micro |      87.17 |      90.33 |      87.50 |      88.33
   Macro |      90.43 |      90.83 |      90.78 |      90.81
      EM |      54.67 |      57.33 |      58.67 |      56.00
======================================================================

그래프가 저장되었습니다: experiments/20251215_165109/accuracy_comparison.png
